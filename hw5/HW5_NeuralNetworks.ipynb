{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcohjPJpdtXn"
   },
   "source": [
    "# Homework 5: Neural Networks for Recognition\n",
    "\n",
    "#### **For each question please refer to the handout for more details.**\n",
    "\n",
    "Programming questions begin at **Q2**. **Remember to run all cells** and save the notebook to your local machine as a pdf for gradescope submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ3ENHvRNMe0"
   },
   "source": [
    "Pablo Agustin Ortega Kral (portegak)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxPtNfTRd_v2"
   },
   "source": [
    "# Q1 Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVBrea_DNsxI"
   },
   "source": [
    "## Q1.1 (3 points)\n",
    "\n",
    "Softmax is defined as below, for each index $i$ in a vector $x \\in \\mathbb{R}^d$.\n",
    "$$ softmax(x)_i = \\frac{e^{x_i}}{\\sum_j e^{x_j}} $$\n",
    "Prove that softmax is invariant to translation, that is\n",
    "$$ softmax(x) = softmax(x + c) \\quad \\forall c \\in \\mathbb{R}.$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**\n",
    "\n",
    "By expanding softmax we see that\n",
    "\n",
    "$$\\text{softmax}(x+c) = \\frac{e^{x_i + c}}{\\sum_j e^{x_j +c}}$$\n",
    "\n",
    "By separating the exponentiation sum, we can re-write as \n",
    "$$\\text{softmax}(x+c) = \\frac{e^{x_i} e^{c}}{\\sum_j e^{x_j} e^{c}}$$\n",
    "$$\\text{softmax}(x+c) = \\frac{e^{c} e^{x_i} }{e^{c} \\sum_j e^{x_j} }$$\n",
    "$$\\text{softmax}(x+c) = \\frac{e^{c}}{e^{c}} \\cdot \\frac{e^{x_i} }{ \\sum_j e^{x_j} } = 1 \\cdot \\frac{e^{x_i} }{ \\sum_j e^{x_j} }$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\text{softmax}(x+c) = \\text{softmax}(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 (3 points)\n",
    "\n",
    "Often we use $c = -\\max x_i$. Why is that a good idea? (Tip: consider the range of values that numerator will have with $c=0$ and $c = -\\max x_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8bGdRxTfaW6"
   },
   "source": [
    "**A:** By substracting the max we are esssentially limiting the magnitude that the numerator can take, given that is an exponentiation large numbers can result in high values and cause numerical inestability, floating point and overflow issues. \n",
    "\n",
    "By subtracting the maximum of the vector, the range of exponents for the numerator becomes $[\\text{min } x_i - \\text{max } x_i, 0]$, thus the maximum value of the numerator is capped at 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwAQkjGhiTyj"
   },
   "source": [
    "## Q1.2\n",
    "\n",
    "Softmax can be written as a three-step process, with $s_i = e^{x_i}$, $S = \\sum s_i$ and $softmax(x)_i = \\frac{1}{S} s_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lLuyRJ_QrcU"
   },
   "source": [
    "### Q1.2.1 (1 point)\n",
    "\n",
    "As $x \\in \\mathbb{R}^d$, what are the properties of $softmax(x)$, namely what is the range of each element? What is the sum over all elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY3EjZ0mjCVF"
   },
   "source": [
    "**A:**\n",
    "\n",
    "- $s_i$ has the range of the exponential function, meaning that for any real $x_i$ $s_i > 0$. Thus, $s_i \\in (0, \\inf)$\n",
    "- $\\sum s_i$, given that is the sum of exponetials it shares the same range, however the denominator will be greator than any single term $S > s_i$\n",
    "- $\\frac{1}{S}s_i$, given that $S$ is greater than any $s_i$ the ratio must always be below 1, $\\frac{1}{S}s_i < 1$. Given that the numerator will never be 0.\n",
    "\n",
    "$$ \\frac{1}{S}s_i \\in (0,1) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEP3hCPRjOlK"
   },
   "source": [
    "### Q1.2.2 (1 point)\n",
    "\n",
    "One could say that softmax takes an arbitrary real valued vector $x$ and turns it into a **_probability distribution_**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVSQbaa1jdPw"
   },
   "source": [
    "**A:** We can see that by applying each of the steps in softmax, the resulting elements comply with the properties of a probability distribution\n",
    "\n",
    "- All elements are positive.\n",
    "- Range is $(0,1)$\n",
    "- The sum of elements is 1 $\\sum_i \\text{softmax}(x) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyzagV0ejnFd"
   },
   "source": [
    "### Q1.2.3 (1 point)\n",
    "\n",
    "Now explain the role of each step in the multi-step process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C7xrhpsjvtY"
   },
   "source": [
    "**A:**\n",
    "\n",
    "- $s_i = e^{x_i}$ maps each element to a nonegative space, where increasing $x_i$ results in increasing the magnitude of $s_i$.\n",
    "\n",
    "- $S = \\sum s_i$ provides a normalization term. By taking the sum of the exponentiation, we ensure that no single element of $s_i$ will be larger than $S$ and therefore the ration will always be below 1.\n",
    "\n",
    "- $1/S s_i$ by applying the normalization term we ensure that each element is the resulting vector is a nonegative in the range $(0,1)$ and will sum up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JC4KViegj4gB"
   },
   "source": [
    "## Q1.3 (3 points)\n",
    "\n",
    "Show that multi-layer neural networks without a non-linear activation function are equivalent to linear regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov_We6Y8kVtQ"
   },
   "source": [
    "**A:** A multilayer network with no non-linear action function between layers is a single linear transformation. Assuming a network with $L$ layers, \n",
    "\n",
    "$$ y = W^L(W^{L-1}(\\dots (W^1x + b^{1})) + b^{L-1}) + b^L$$\n",
    "\n",
    "The matrix of weights can be all combined into an effective weight matrix, as well as the bias vectors.\n",
    "\n",
    "$$ y = Wx + b$$\n",
    "\n",
    "Thefore, by trainig this nework, we are essentially solving the linear regresion problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8Flb0zAkZuc"
   },
   "source": [
    "## Q1.4 (3 points)\n",
    "\n",
    "Given the sigmoid activation function $\\sigma(x) = \\frac{1}{1+e^{-x}}$, derive the gradient of the sigmoid function and show that it can be written as a function of $\\sigma(x)$ (without having access to $x$ directly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pvielTIkj3k"
   },
   "source": [
    "**A:** Applying the chain rule,\n",
    "\n",
    "$$ \\frac{d}{dx} \\sigma (x) = \\frac{e^{-x}}{(1+e^{-x})^2}$$\n",
    "\n",
    "Expanding, \n",
    "\n",
    "$$ \\frac{d}{dx} \\sigma (x) = \\frac{e^{-x}}{1+e^{-x}} \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "We can further express \n",
    "\n",
    "$$ \\frac{e^{-x}}{1+e^{-x}} =  \\frac{(1+e^{-x}) -1}{1+e^{-x}} = \\frac{(1+e^{-x})}{1+e^{-x}} - \\frac{1}{1+e^{-x}} = 1 - \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "$$ \\frac{d}{dx} \\sigma (x) = (1 - \\frac{1}{1+e^{-x}})\\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "We can then subsitute $\\sigma (x)$ into the expression such that,\n",
    "\n",
    "$$ \\frac{d}{dx} \\sigma (x) = (1 - \\sigma (x)) \\sigma (x)$$\n",
    "\n",
    "Therefore, the derivative of sigma can be expressed entirely in terms of itself, without needing access to $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRfJcVgIkse3"
   },
   "source": [
    "## Q1.5 (12 points)\n",
    "\n",
    "Given $y = Wx + b$ (or $y_i = \\sum_{j=1}^d  x_{j} W_{ij} + b_i$), and the gradient of some loss $J$ (a scalar) with respect to $y$, show how to get the gradients $\\frac{\\partial J}{\\partial W}$, $\\frac{\\partial J}{\\partial x}$ and $\\frac{\\partial J}{\\partial b}$. Be sure to do the derivatives with scalars and re-form the matrix form afterwards. Here are some notional suggestions.\n",
    "$$ x \\in \\mathbb{R}^{d \\times 1} \\quad y \\in \\mathbb{R}^{k \\times 1} \\quad W \\in \\mathbb{R}^{k \\times d} \\quad b \\in \\mathbb{R}^{k \\times 1} \\quad \\frac{\\partial J}{\\partial y} = \\delta \\in \\mathbb{R}^{k \\times 1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwht2EJvlHs6"
   },
   "source": [
    "**A:** \n",
    "\n",
    "Gicen that $J$ is a loss respect to $y$ and were are giving the value of it's partial, we can use it to build the other expressions through chain rule.\n",
    "\n",
    "1. $\\frac{\\partial J}{\\partial W}$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_{ij}} = \\sum_{n = 1}^{k} \\frac{\\partial J}{\\partial y_n} \\frac{\\partial y_n}{\\partial W_{ij}}  $$\n",
    "\n",
    "Given that $\\frac{\\partial J}{\\partial y_n}$ is a scalar,\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_{ij}} = \\sum_{n = 1}^{k} \\delta_n \\frac{\\partial y_n}{\\partial W_{ij}}  $$\n",
    "\n",
    "Given that $y_n = W_{ij} x_j + b_n$, we see that we only can take a partial derivative when $n$ is a row of $W_{ij}$, such that\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_{ij}} =  \\sum_{n = 1}^{k} \\delta_n x_j = \\delta_i x_j$$\n",
    "\n",
    "In matrix form, \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W} = \\delta \\cdot x^T$$\n",
    "---\n",
    "\n",
    "2. $\\frac{\\partial J}{\\partial x}$\n",
    "\n",
    "$$ = \\sum_{n = 1}^{k} \\frac{\\partial J}{\\partial y_n} \\frac{\\partial y_n}{\\partial x_j} $$\n",
    "\n",
    "We can see that $\\frac{\\partial y_n}{\\partial x_j} = W_{nj}$, therefore\n",
    "\n",
    "$$ = \\sum_{n = 1}^{k} \\delta_n W_{nj} $$\n",
    "\n",
    "In matrix for, \n",
    "\n",
    "$$\\frac{\\partial J}{\\partial x} = W^T \\delta$$\n",
    "\n",
    "---\n",
    "\n",
    "3. $\\frac{\\partial J}{\\partial b}$\n",
    "\n",
    "$$ = \\sum_{n = 1}^{k} \\frac{\\partial J}{\\partial y_n} \\frac{\\partial y_n}{\\partial b_i} $$\n",
    "$$ = \\sum_{n = 1}^{k} \\delta_n \\frac{\\partial y_n}{\\partial b_i}$$\n",
    "\n",
    "Again, we can only take a partial derivative when $n == 1$. In this case, $y_n = W_{ij}x_j + b_i \\therefore \\frac{\\partial y_n}{\\partial b_i} = 1$.\n",
    "\n",
    "$$ = \\sum_{n = 1}^{k} \\delta_n 1$$\n",
    "\n",
    "In matrix form, \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\delta $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90MKQWDOfJ4O"
   },
   "source": [
    "## Q1.6\n",
    "When the neural network applies the elementwise activation function (such as sigmoid), the gradient of the activation function scales the backpropogation update. This is directly from the chain rule, $\\frac{d}{d x} f(g(x)) = f'(g(x)) g'(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozWYiNGTlTIU"
   },
   "source": [
    "### Q1.6.1 (1 point)\n",
    "\n",
    "Consider the sigmoid activation function for deep neural networks. Why might it lead to a \"vanishing gradient\" problem if it is used for many layers (consider plotting the gradient you derived in Q1.4)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbXpahyMlj8r"
   },
   "source": [
    "**A:** Recall that $ \\sigma (x)^{\\prime} = (1 - \\sigma (x)) \\sigma (x)$. This means that the derivative has a range of values between $[0,0.25]$. When considering this within the chain rule, we are essentially scaling down each layer by multiplying by small magnitudes (or in some cases en 0!). Because of this, sigmoids should be restricted to the output layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riqojST1lnoS"
   },
   "source": [
    "### Q1.6.2 (1 point)\n",
    "Often it is replaced with $\\tanh(x) = \\frac{1-e^{-2x}}{1+e^{-2x}}$. What are the output ranges of both $\\tanh$ and sigmoid? Why might we prefer $\\tanh$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93ELzc12l3ya"
   },
   "source": [
    "- $\\sigma (x) \\in (0,1)$ \n",
    "- $\\tanh (x) \\in (-1,1)$\n",
    "\n",
    "We can see that the lower bound of tanh is -1. One nice property of this is we have effectively double the expressive range when compared to sigmoid. Other benefits include that tanh is symetric respect to the origin, which can help to produce more evenly sampled gradients which in turn can aid in smoother convergance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnTfGXcrl_Oc"
   },
   "source": [
    "### Q1.6.3 (1 point)\n",
    "Why does $\\tanh(x)$ have less of a vanishing gradient problem? (plotting the gradients helps! for reference: $\\tanh'(x) = 1 - \\tanh(x)^2$)\n",
    "\n",
    "*A:* Even though the lower bound of the gradient is still 0, meaning that vanishing gradeints could still occur, we see that most values are around 1, leadign to less reduction of the gradient on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SxSA6uxRmKL-"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigma_prime(x):\n",
    "    return sigma(x) * (1 - sigma(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "x = np.linspace(-10, 10, 100)\n",
    "ax.plot(x, sigma_prime(x), label='Derivative of Sigmoid')\n",
    "ax.plot(x, tanh_prime(x), label='Derivative of Tanh')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3GaT-ZumRdA"
   },
   "source": [
    "### Q1.6.4 (1 point)\n",
    "$\\tanh$ is a scaled and shifted version of the sigmoid. Show how $\\tanh(x)$ can be written in terms of $\\sigma(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6O2FQxYmWzR"
   },
   "source": [
    "Considering $\\sigma (x) = \\frac{1}{1+e^-x} \\therefore \\sigma (2x) = \\frac{1}{1+e^-2x} $.\n",
    "\n",
    "We begin by rewritting the numerator in terms of $1+e^-2x$,\n",
    "\n",
    "$$ \\text{tanh}(x) = \\frac{2-(1+e^{-2x})}{1 + e^{-2x}} $$\n",
    "$$ \\text{tanh}(x) = \\frac{2}{1 + e^{-2x}} - \\frac{(1+e^{-2x})}{1 + e^{-2x}}$$\n",
    "$$ \\text{tanh}(x) = \\frac{2}{1 + e^{-2x}} - 1$$\n",
    "\n",
    "There we can see that,\n",
    "\n",
    "$$ \\text{tanh}(x) = 2\\sigma(2x) - 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTtEm_BsiBa9"
   },
   "source": [
    "# Q2 Implement a Fully Connected Network\n",
    "\n",
    "Run the following code to import the modules you'll need. When implementing the functions in Q2, make sure you run the test code (provided after Q2.3) along the way to check if your implemented functions work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nT0pjHBzJjHd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.color\n",
    "import skimage.restoration\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import skimage.segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn2ROCmuiK3i"
   },
   "source": [
    "## Q2.1 Network Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhVvjmznihUr"
   },
   "source": [
    "### Q2.1.1 (3 points)\n",
    "\n",
    "Why is it not a good idea to initialize a network with all zeros? If you imagine that every layer has weights and biases, what can a zero-initialized network output be after training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B7sAkKJiwVX"
   },
   "source": [
    "**A:**  Setting initial values as 0 cause all layers to give the same output and the same gradient, meaning that the layers would be updated uniformly. This could result in the network giving the same output regardless of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv9dtEXCjf_R"
   },
   "source": [
    "### Q2.1.2 (3 points)\n",
    "\n",
    "Implement the initialize_weights() function to initialize the weights for a single layer with Xavier initialization, where $Var[w] = \\frac{2}{n_{in}+ n_{out}} $ where $n$ is the dimensionality of the vectors and you use a uniform distribution to sample random numbers (see eq 16 in [Glorot et al])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VX7OdRphj2XE"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.1.2 ##############################\n",
    "def initialize_weights(in_size, out_size, params, name=''):\n",
    "    \"\"\"\n",
    "    we will do XW + b, with the size of the input data array X being [number of examples, in_size]\n",
    "    the weights W should be initialized as a 2D array\n",
    "    the bias vector b should be initialized as a 1D array, not a 2D array with a singleton dimension\n",
    "    the output of this layer should be in size [number of examples, out_size]\n",
    "    \"\"\"\n",
    "    W, b  = None, None\n",
    "    bound = np.sqrt(6) / np.sqrt(in_size + out_size) # Use the formula for Xavier initialization\n",
    "    W     = np.random.uniform(-bound, bound, (in_size, out_size))\n",
    "    b    = np.zeros((out_size)) # Bias is a 1D array\n",
    "    \n",
    "    params['W' + name] = W\n",
    "    params['b' + name] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUGYc0XCn4rk"
   },
   "source": [
    "### Q2.1.3 (2 points)\n",
    "\n",
    "Why do we scale the initialization depending on layer size (see Fig 6 in the [Glorot et al])?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nL1GJX7CoDP0"
   },
   "source": [
    " **A:** By applying this, we can ensure more consistency between action values accross all the layers. This prevents a single layer from dominating with a peak value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAQJJ247pRZ2"
   },
   "source": [
    "## Q2.2 Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AzMm0dnpbLo"
   },
   "source": [
    "### Q2.2.1 (4 points)\n",
    "\n",
    "Implement the sigmoid() function, which computes the elementwise sigmoid activation of entries in an input array. Then implement the forward() function which computes forward propagation for a single layer, namely $y = \\sigma(X W + b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LCyYmPNUqHof"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.2.1 ##############################\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Implement an elementwise sigmoid activation function on the input x,\n",
    "    where x is a numpy array of size [number of examples, number of output dimensions]\n",
    "    \"\"\"\n",
    "    res = None\n",
    "    res = 1 / (1 + np.exp(-x))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3xg4aSq4p-Eq"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.2.1 ##############################\n",
    "def forward(X,params,name='',activation=sigmoid):\n",
    "    \"\"\"\n",
    "    Do a forward pass for a single layer that computes the output: activation(XW + b)\n",
    "\n",
    "    Keyword arguments:\n",
    "    X -- input numpy array of size [number of examples, number of input dimensions]\n",
    "    params -- a dictionary containing parameters, as how you initialized in Q 2.1.2\n",
    "    name -- name of the layer\n",
    "    activation -- the activation function (default is sigmoid)\n",
    "    \"\"\"\n",
    "    # compute the output values before and after the activation function\n",
    "    pre_act, post_act = None, None\n",
    "    # get the layer parameters\n",
    "    W = params['W' + name]\n",
    "    b = params['b' + name]\n",
    "\n",
    "    pre_act  = X @ W + b\n",
    "    post_act = sigmoid(pre_act)\n",
    "\n",
    "    params['cache_' + name] = (X, pre_act, post_act)\n",
    "\n",
    "    return post_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg2eLRDfr3Gd"
   },
   "source": [
    "### Q2.2.2 (3 points)\n",
    "\n",
    "Implement the softmax() function. Be sure to use the numerical stability trick you derived in Q1.1 softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9DpxFAHssNxB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09003057 0.24472847 0.66524096]\n",
      " [0.09003057 0.24472847 0.66524096]]\n"
     ]
    }
   ],
   "source": [
    "############################## Q 2.2.2  ##############################\n",
    "def softmax(x, numerically_stable=True):\n",
    "    \"\"\"\n",
    "    x is a numpy array of size [number of examples, number of classes]\n",
    "    softmax should be done for each row\n",
    "    \"\"\"\n",
    "    res = None\n",
    "    vals = np.exp(x) \n",
    "    if numerically_stable:\n",
    "        # Subtract the max value in each row to avoid overflow\n",
    "        max_vals = np.max(x, axis=-1, keepdims=True)\n",
    "        vals = np.exp(x - max_vals)\n",
    "    norm_factor = np.sum(vals, axis=-1, keepdims=True)\n",
    "    \n",
    "    res = vals / norm_factor\n",
    "    assert np.allclose(np.sum(res, axis=-1), 1), \"Softmax output should sum to 1\"\n",
    "    return res\n",
    "\n",
    "test_softmax = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(softmax(test_softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTUXP5WcNBll"
   },
   "source": [
    "### Q2.2.3 (3 points)\n",
    "\n",
    "Implement the compute_loss_and_acc() function to compute the accuracy given a set of labels, along with the scalar loss across the data. The loss function generally used for classification is the cross-entropy loss.\n",
    "\n",
    "$$L_{f}(\\mathbf{D}) = - \\sum_{(x, y)\\in \\mathbf{D}}y \\cdot \\log(f(x))$$\n",
    "\n",
    "Here $\\mathbf{D}$ is the full training dataset of $N$ data samples $x$ (which are $D \\times 1$ vectors, $D$ is the dimensionality of data) and labels $y$ (which are $C\\times 1$ one-hot vectors, $C$ is the number of classes), and $f:\\mathbb{R}^D\\to[0,1]^C$ is the classifier which outputs the probabilities for the classes.\n",
    "The $\\log$ is the natural $\\log$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kd3f9MSYOM0J"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.2.3 ##############################\n",
    "def compute_loss_and_acc(y, probs):\n",
    "    \"\"\"\n",
    "    compute total loss and accuracy\n",
    "\n",
    "    Keyword arguments:\n",
    "    y -- the labels, which is a numpy array of size [number of examples, number of classes]\n",
    "    probs -- the probabilities output by the classifier, i.e. f(x), which is a numpy array of size [number of examples, number of classes]\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    \n",
    "    loss, acc = None, None\n",
    "    # Using cross-entropy loss\n",
    "    loss = -np.sum(y * np.log(probs + eps)) \n",
    "    \n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    gt = np.argmax(y, axis=1)\n",
    "    acc = np.mean(preds == gt)\n",
    "    \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4_NIHjVQe6N"
   },
   "source": [
    "## Q2.3 Backwards Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI0ZrHe4QsO-"
   },
   "source": [
    "### Q2.3 (7 points)\n",
    "\n",
    "Implement the backwards() function to compute backpropagation for a single layer, given the original weights, the appropriate intermediate results, and the gradient with respect to the loss. You should return the gradient with respect to the inputs (grad_X) so that it can be used in the backpropagation for the previous layer. As a size check, your gradients should have the same dimensions as the original objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "WVvhSlnxQ7f6"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.3 ##############################\n",
    "def sigmoid_deriv(post_act):\n",
    "    \"\"\"\n",
    "    we give this to you, because you proved it in Q1.4\n",
    "    it's a function of the post-activation values (post_act)\n",
    "    \"\"\"\n",
    "    res = post_act*(1.0-post_act)\n",
    "    return res\n",
    "\n",
    "def backwards(delta,params,name='',activation_deriv=sigmoid_deriv):\n",
    "    \"\"\"\n",
    "    Do a backpropagation pass for a single layer.\n",
    "\n",
    "    Keyword arguments:\n",
    "    delta -- gradients of the loss with respect to the outputs (errors to back propagate), in [number of examples, number of output dimensions]\n",
    "    params -- a dictionary containing parameters, as how you initialized in Q 2.1.2\n",
    "    name -- name of the layer\n",
    "    activation_deriv -- the derivative of the activation function\n",
    "    \"\"\"\n",
    "    grad_X, grad_W, grad_b = None, None, None\n",
    "    # everything you may need for this layer\n",
    "    W = params['W' + name]\n",
    "    b = params['b' + name]\n",
    "    X, pre_act, post_act = params['cache_' + name]\n",
    "\n",
    "    # by the chain rule, do the derivative through activation first\n",
    "    # (don't forget activation_deriv is a function of post_act)\n",
    "    # then compute the gradients w.r.t W, b, and X\n",
    "    f_prime = activation_deriv(post_act)\n",
    "    grad_act = delta * f_prime\n",
    "    \n",
    "    grad_W  = X.T @ grad_act\n",
    "    grad_X  = grad_act @ W.T\n",
    "    grad_b  = np.sum(grad_act, axis=0)\n",
    "\n",
    "    # store the gradients\n",
    "    params['grad_W' + name] = grad_W\n",
    "    params['grad_b' + name] = grad_b\n",
    "    return grad_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXlcvTqnUmRp"
   },
   "source": [
    "Make sure you run below test code along the way to check if your implemented functions work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "j_-d1LydiSG6"
   },
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    # Define a linear activation, which can be used to construct a \"no activation\" layer\n",
    "    return x\n",
    "\n",
    "def linear_deriv(post_act):\n",
    "    return np.ones_like(post_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1711076133887,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "vnmPGUYtQKTU",
    "outputId": "9b15a35a-bfff-4754-cd3c-2246132bfa3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (40, 2) labels shape: (40, 4)\n",
      "Q 2.1.2: 0.0, 0.07\n",
      "Q 2.1.2: 0.0, 0.05\n",
      "Q 2.2.1: sigmoid outputs should be zero and one\t 0.0 1.0\n",
      "Q 2.2.2: 0.36748279937040407 2.192427219428363 2.274970642862028\n",
      "Q 2.2.3 loss: 23.55679331040005, acc:0.25\n",
      "Q 2.3 Wlayer1 (2, 25) (2, 25)\n",
      "Q 2.3 Woutput (25, 4) (25, 4)\n",
      "Q 2.3 blayer1 (25,) (25,)\n",
      "Q 2.3 boutput (4,) (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403413/3225249788.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "# generate some fake data\n",
    "# feel free to plot it in 2D, what do you think these 4 classes are?\n",
    "g0 = np.random.multivariate_normal([3.6,40],[[0.05,0],[0,10]],10)\n",
    "g1 = np.random.multivariate_normal([3.9,10],[[0.01,0],[0,5]],10)\n",
    "g2 = np.random.multivariate_normal([3.4,30],[[0.25,0],[0,5]],10)\n",
    "g3 = np.random.multivariate_normal([2.0,10],[[0.5,0],[0,10]],10)\n",
    "x = np.vstack([g0,g1,g2,g3])\n",
    "\n",
    "# we will do XW + B in the forward pass\n",
    "# this implies that the data X is in [number of examples, number of input dimensions]\n",
    "\n",
    "# create labels\n",
    "y_idx = np.array([0 for _ in range(10)] + [1 for _ in range(10)] + [2 for _ in range(10)] + [3 for _ in range(10)])\n",
    "# turn to one-hot encoding, this implies that the labels y is in [number of examples, number of classes]\n",
    "y = np.zeros((y_idx.shape[0],y_idx.max()+1))\n",
    "y[np.arange(y_idx.shape[0]),y_idx] = 1\n",
    "print(\"data shape: {} labels shape: {}\".format(x.shape, y.shape))\n",
    "\n",
    "# parameters in a dictionary\n",
    "params = {}\n",
    "\n",
    "# Q 2.1.2\n",
    "# we will build a two-layer neural network\n",
    "# first, initialize the weights and biases for the two layers\n",
    "# the first layer, in_size = 2 (the dimension of the input data), out_size = 25 (number of neurons)\n",
    "initialize_weights(2,25,params,'layer1')\n",
    "# the output layer, in_size = 25 (number of neurons), out_size = 4 (number of classes)\n",
    "initialize_weights(25,4,params,'output')\n",
    "assert(params['Wlayer1'].shape == (2,25))\n",
    "assert(params['blayer1'].shape == (25,))\n",
    "assert(params['Woutput'].shape == (25,4))\n",
    "assert(params['boutput'].shape == (4,))\n",
    "\n",
    "# with Xavier initialization\n",
    "# expect the means close to 0, variances in range [0.05 to 0.12]\n",
    "print(\"Q 2.1.2: {}, {:.2f}\".format(params['blayer1'].mean(),params['Wlayer1'].std()**2))\n",
    "print(\"Q 2.1.2: {}, {:.2f}\".format(params['boutput'].mean(),params['Woutput'].std()**2))\n",
    "\n",
    "# Q 2.2.1\n",
    "# implement sigmoid\n",
    "# there might be an overflow warning due to exp(1000)\n",
    "test = sigmoid(np.array([-1000,1000]))\n",
    "print('Q 2.2.1: sigmoid outputs should be zero and one\\t',test.min(),test.max())\n",
    "# a forward pass on the first layer, with sigmoid activation\n",
    "h1 = forward(x,params,'layer1',sigmoid)\n",
    "assert(h1.shape == (40, 25))\n",
    "\n",
    "# Q 2.2.2\n",
    "# implement softmax\n",
    "# a forward pass on the second layer (the output layer), with softmax so that the outputs are class probabilities\n",
    "probs = forward(h1,params,'output',softmax)\n",
    "# make sure you understand these values!\n",
    "# should be positive, 1 (or very close to 1), 1 (or very close to 1)\n",
    "print('Q 2.2.2:',probs.min(),min(probs.sum(1)),max(probs.sum(1)))\n",
    "assert(probs.shape == (40,4))\n",
    "\n",
    "# Q 2.2.3\n",
    "# implement compute_loss_and_acc\n",
    "loss, acc = compute_loss_and_acc(y, probs)\n",
    "# should be around -np.log(0.25)*40 [~55] or higher, and 0.25\n",
    "# if it is not, check softmax!\n",
    "print(\"Q 2.2.3 loss: {}, acc:{:.2f}\".format(loss,acc))\n",
    "\n",
    "# Q 2.3\n",
    "# here we cheat for you, you can use it in the training loop in Q2.4\n",
    "# the derivative of cross-entropy(softmax(x)) is probs - 1[correct actions]\n",
    "delta1 = probs - y\n",
    "\n",
    "# backpropagation for the output layer\n",
    "# we already did derivative through softmax when computing delta1 as above\n",
    "# so we pass in a linear_deriv, which is just a vector of ones to make this a no-op\n",
    "delta2 = backwards(delta1,params,'output',linear_deriv)\n",
    "# backpropagation for the first layer\n",
    "backwards(delta2,params,'layer1',sigmoid_deriv)\n",
    "\n",
    "# the sizes of W and b should match the sizes of their gradients\n",
    "for k,v in sorted(list(params.items())):\n",
    "    if 'grad' in k:\n",
    "        name = k.split('_')[1]\n",
    "        # print the size of the gradient and the size of the parameter, the two sizes should be the same\n",
    "        print('Q 2.3',name,v.shape, params[name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEKUvkHFpjPB"
   },
   "source": [
    "## Q2.4 Training Loop: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tguaFmjxT_jw"
   },
   "source": [
    "### Q2.4 (5 points)\n",
    "Implement the get_random_batches() function that takes the entire dataset (x and y) as input and splits it into random batches. Write a training loop that iterates over the batches, does forward and backward propagation, and applies a gradient update. The provided code samples batch only once, but it is also common to sample new random batches at each epoch. You may optionally try both strategies and note any difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mf6nhd3IOFjh"
   },
   "outputs": [],
   "source": [
    "############################## Q 2.4 ##############################\n",
    "def get_random_batches(x,y,batch_size):\n",
    "    \"\"\"\n",
    "    split x (data) and y (labels) into random batches\n",
    "    return a list of [(batch1_x,batch1_y)...]\n",
    "    \"\"\"\n",
    "    import random\n",
    "    batches = []\n",
    "\n",
    "    # shuffle the data\n",
    "    data = list(zip(x, y))\n",
    "    random.shuffle(data)\n",
    "    x, y = zip(*data)\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_sample = x[i:i + batch_size]\n",
    "        y_sample = y[i:i + batch_size]\n",
    "        batches.append((x_sample, y_sample))\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1711076133888,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "bVLgxxAvPO-b",
    "outputId": "19f831c0-8772-4cc2-f4a9-ba5f409aea43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 5, 5, 5]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Q 2.4\n",
    "batches = get_random_batches(x,y,5)\n",
    "batch_num = len(batches)\n",
    "# print batch sizes\n",
    "print([_[0].shape[0] for _ in batches])\n",
    "print(batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1711076134531,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "oH7JWuCAU2Di",
    "outputId": "d2a588e8-c63b-43b6-8122-67daf99d1b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr: 00 \t loss: 30.58 \t acc : 0.67\n",
      "itr: 100 \t loss: 29.64 \t acc : 0.67\n",
      "itr: 200 \t loss: 28.83 \t acc : 0.70\n",
      "itr: 300 \t loss: 28.02 \t acc : 0.72\n",
      "itr: 400 \t loss: 27.13 \t acc : 0.77\n"
     ]
    }
   ],
   "source": [
    "############################## Q 2.4 ##############################\n",
    "# WRITE A TRAINING LOOP HERE\n",
    "max_iters = 500\n",
    "learning_rate = 1e-3\n",
    "# with default settings, you should get loss <= 35 and accuracy >= 75%\n",
    "layers = ['layer1', 'output']\n",
    "for itr in range(max_iters):\n",
    "    total_loss = 0\n",
    "    avg_acc = 0\n",
    "    for xb,yb in batches:\n",
    "        # forward\n",
    "        features = forward(xb, params, layers[0], sigmoid)\n",
    "        out_prob = forward(features,params ,layers[1], softmax)\n",
    "        # loss\n",
    "        loss, acc  = compute_loss_and_acc(yb, out_prob)\n",
    "        total_loss += loss \n",
    "        avg_acc    += acc  / batch_num  \n",
    "        # backward\n",
    "        grad0 = out_prob - yb\n",
    "        grad_prev = backwards(grad0, params, layers[1], linear_deriv)\n",
    "        for l in layers[0::-1]:\n",
    "            grad_prev = backwards(grad_prev, params, l, sigmoid_deriv)\n",
    "        \n",
    "        # apply gradient to update the parameters\n",
    "        for l in layers:\n",
    "            params['W' + l] -= learning_rate * params['grad_W' + l]\n",
    "            params['b' + l] -= learning_rate * params['grad_b' + l]\n",
    "        \n",
    "    if itr % 100 == 0:\n",
    "        print(\"itr: {:02d} \\t loss: {:.2f} \\t acc : {:.2f}\".format(itr,total_loss,avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZfeCRPGfBrY"
   },
   "source": [
    "# Q3 Training Models\n",
    "\n",
    "Run below code to download and put the unzipped data in '/content/data' folder.\n",
    "\n",
    "We have provided you three data .mat files to use for this section.\n",
    "The training data in nist36_train.mat contains samples for each of the 26 upper-case letters of the alphabet and the 10 digits. This is the set you should use for training your network.\n",
    "The cross-validation set in nist36_valid.mat contains samples from each class, and should be used in the training loop to see how the network is performing on data that it is not training on. This will help to spot overfitting.\n",
    "Finally, the test data in nist36_test.mat contains testing data, and should be used for the final evaluation of your best model to see how well it will generalize to new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6_6ehqPJg7AR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-09 22:03:40--  http://www.cs.cmu.edu/~lkeselma/16720a_data/data.zip\n",
      "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
      "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 216305627 (206M) [application/zip]\n",
      "Saving to: ‘data/data.zip’\n",
      "\n",
      "data/data.zip       100%[===================>] 206.28M   111MB/s    in 1.9s    \n",
      "\n",
      "2025-04-09 22:03:43 (111 MB/s) - ‘data/data.zip’ saved [216305627/216305627]\n",
      "\n",
      "Archive:  data/data.zip\n",
      "warning:  stripped absolute path spec from /\n",
      "mapname:  conversion of  failed\n",
      "  inflating: data/nist26_valid.mat   \n",
      "  inflating: data/nist26_model_60iters.mat  \n",
      "  inflating: data/nist36_test.mat    \n",
      "  inflating: data/nist26_test.mat    \n",
      "  inflating: data/nist26_train.mat   \n",
      "  inflating: data/nist36_train.mat   \n",
      "  inflating: data/nist36_valid.mat   \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data'):\n",
    "  os.mkdir('data')\n",
    "  !wget http://www.cs.cmu.edu/~lkeselma/16720a_data/data.zip -O data/data.zip\n",
    "  !unzip \"data/data.zip\" -d \"data\"\n",
    "  os.system(\"rm data/data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1711076134531,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "an8MYapMhaei",
    "outputId": "bdb3b5a3-aa2b-4259-d849-a9192d1ca2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mnist26_model_60iters.mat\u001b[0m*  \u001b[01;32mnist26_valid.mat\u001b[0m*  \u001b[01;32mnist36_valid.mat\u001b[0m*\n",
      "\u001b[01;32mnist26_test.mat\u001b[0m*           \u001b[01;32mnist36_test.mat\u001b[0m*\n",
      "\u001b[01;32mnist26_train.mat\u001b[0m*          \u001b[01;32mnist36_train.mat\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHQYXcdLf8dJ"
   },
   "source": [
    "## Q3.1 (5 points)\n",
    "\n",
    "Train a network from scratch. Use a single hidden layer with 64 hidden units, and train for at least 50 epochs. The script will generate two plots:\n",
    "    \n",
    "(1) the accuracy on both the training and validation set over the epochs, and\n",
    "    \n",
    "(2) the cross-entropy loss averaged over the data.\n",
    "    \n",
    "Tune the batch size and learning rate for accuracy on the validation set of at least 75\\%. Hint: Use fixed random seeds to improve reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1568,
     "status": "ok",
     "timestamp": 1711076136098,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "UjgNQIV_f3zK",
    "outputId": "30de16f5-8b26-40b4-9fa5-5f95bee0cf67"
   },
   "outputs": [],
   "source": [
    "train_data = scipy.io.loadmat('data/nist36_train.mat')\n",
    "valid_data = scipy.io.loadmat('data/nist36_valid.mat')\n",
    "test_data = scipy.io.loadmat('data/nist36_test.mat')\n",
    "\n",
    "train_x, train_y = train_data['train_data'], train_data['train_labels']\n",
    "valid_x, valid_y = valid_data['valid_data'], valid_data['valid_labels']\n",
    "test_x, test_y = test_data['test_data'], test_data['test_labels']\n",
    "\n",
    "if True: # view the data\n",
    "    for crop in train_x:\n",
    "        plt.imshow(crop.reshape(32,32).T, cmap=\"Greys\")\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28856,
     "status": "ok",
     "timestamp": 1711076164952,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "FTHdbIAHqc98",
    "outputId": "733659f5-5c30-41e3-87dc-1d459e87a1ec"
   },
   "outputs": [],
   "source": [
    "############################## Q 3.1 ##############################\n",
    "max_iters = 50\n",
    "# pick a batch size, learning rate\n",
    "batch_size = None\n",
    "learning_rate = None\n",
    "hidden_size = 64\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n",
    "\n",
    "\n",
    "batches = get_random_batches(train_x,train_y,batch_size)\n",
    "batch_num = len(batches)\n",
    "\n",
    "params = {}\n",
    "\n",
    "# initialize layers\n",
    "initialize_weights(train_x.shape[1], hidden_size, params, \"layer1\")\n",
    "initialize_weights(hidden_size, train_y.shape[1], params, \"output\")\n",
    "layer1_W_initial = np.copy(params[\"Wlayer1\"]) # copy for Q3.3\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "for itr in range(max_iters):\n",
    "    # record training and validation loss and accuracy for plotting\n",
    "    h1 = forward(train_x,params,'layer1',sigmoid)\n",
    "    probs = forward(h1,params,'output',softmax)\n",
    "    loss, acc = compute_loss_and_acc(train_y, probs)\n",
    "    train_loss.append(loss/train_x.shape[0])\n",
    "    train_acc.append(acc)\n",
    "\n",
    "    h1 = forward(valid_x,params,'layer1',sigmoid)\n",
    "    probs = forward(h1,params,'output',softmax)\n",
    "    loss, acc = compute_loss_and_acc(valid_y, probs)\n",
    "    valid_loss.append(loss/valid_x.shape[0])\n",
    "    valid_acc.append(acc)\n",
    "\n",
    "    total_loss = 0\n",
    "    avg_acc = 0\n",
    "    for xb,yb in batches:\n",
    "        # training loop can be exactly the same as q2!\n",
    "        ##########################\n",
    "        ##### your code here #####\n",
    "        ##########################\n",
    "\n",
    "\n",
    "    if itr % 2 == 0:\n",
    "        print(\"itr: {:02d}   loss: {:.2f}   acc: {:.2f}\".format(itr,total_loss,avg_acc))\n",
    "\n",
    "# record final training and validation accuracy and loss\n",
    "h1 = forward(train_x,params,'layer1',sigmoid)\n",
    "probs = forward(h1,params,'output',softmax)\n",
    "loss, acc = compute_loss_and_acc(train_y, probs)\n",
    "train_loss.append(loss/train_x.shape[0])\n",
    "train_acc.append(acc)\n",
    "\n",
    "h1 = forward(valid_x,params,'layer1',sigmoid)\n",
    "probs = forward(h1,params,'output',softmax)\n",
    "loss, acc = compute_loss_and_acc(valid_y, probs)\n",
    "valid_loss.append(loss/valid_x.shape[0])\n",
    "valid_acc.append(acc)\n",
    "\n",
    "# report validation accuracy; aim for 75%\n",
    "print('Validation accuracy: ', valid_acc[-1])\n",
    "\n",
    "# compute and report test accuracy\n",
    "h1 = forward(test_x,params,'layer1',sigmoid)\n",
    "test_probs = forward(h1,params,'output',softmax)\n",
    "_, test_acc = compute_loss_and_acc(test_y, test_probs)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vejbz8LDsjnu"
   },
   "outputs": [],
   "source": [
    "# save the final network\n",
    "import pickle\n",
    "\n",
    "saved_params = {k:v for k,v in params.items() if '_' not in k}\n",
    "with open('/content/q3_weights.pickle', 'wb') as handle:\n",
    "  pickle.dump(saved_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1711076165730,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "1dv8Yg4kssRL",
    "outputId": "a578e8a0-c0bb-4e24-d246-4ac5ef08401a"
   },
   "outputs": [],
   "source": [
    "# plot loss curves\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"training\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"average loss\")\n",
    "plt.xlim(0, len(train_loss)-1)\n",
    "plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy curves\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"training\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlim(0, len(train_acc)-1)\n",
    "plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjhPChazHsnW"
   },
   "source": [
    "## Q3.2 (3 points)\n",
    "\n",
    "The provided code will visualize the first layer weights as 64 32x32 images, both immediately after initialization and after full training. Generate both visualizations. Comment on the learned weights and compare them to the initialized weights. Do you notice any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoZ8iIydKpcE"
   },
   "outputs": [],
   "source": [
    "############################## Q 3.2 ##############################\n",
    "# visualize weights\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title(\"Layer 1 weights after initialization\")\n",
    "plt.axis(\"off\")\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(8, 8), axes_pad=0.05)\n",
    "for i, ax in enumerate(grid):\n",
    "    ax.imshow(layer1_W_initial[:,i].reshape((32, 32)).T)\n",
    "    ax.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "v = np.max(np.abs(params['Wlayer1']))\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title(\"Layer 1 weights after training\")\n",
    "plt.axis(\"off\")\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(8, 8), axes_pad=0.05)\n",
    "for i, ax in enumerate(grid):\n",
    "    ax.imshow(params['Wlayer1'][:,i].reshape((32, 32)).T, vmin=-v, vmax=v)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-KQCS31IRnX"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfEWyqBmkvOs"
   },
   "source": [
    "## Q3.3 (3 points)\n",
    "\n",
    "Use the code in Q3.1 to train and generate accuracy and loss plots for each of these three networks:\n",
    "\n",
    "(1) one with $10$ times your tuned learning rate,\n",
    "    \n",
    "(2) one with one-tenth your tuned learning rate, and\n",
    "\n",
    "(3) one with your tuned learning rate.\n",
    "    \n",
    "Include total of six plots (two will be the same from Q3.1). Comment on how the learning rates affect the training, and report the final accuracy of the best network on the test set. Hint: Use fixed random seeds to improve reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b78p82C9K5J0"
   },
   "outputs": [],
   "source": [
    "############################## Q 3.3 ##############################\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q9vrPV9q3eO"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs1DxVdptsHs"
   },
   "source": [
    "## Q3.4 (3 points)\n",
    "\n",
    "Compute and visualize the confusion matrix of the test data for your best model. Comment on the top few pairs of classes that are most commonly confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8P_EDqYALDkN"
   },
   "outputs": [],
   "source": [
    "############################## Q 3.4 ##############################\n",
    "confusion_matrix = np.zeros((train_y.shape[1],train_y.shape[1]))\n",
    "\n",
    "# compute confusion matrix\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n",
    "\n",
    "\n",
    "\n",
    "# visualize confusion matrix\n",
    "import string\n",
    "plt.imshow(confusion_matrix,interpolation='nearest')\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(36),string.ascii_uppercase[:26] + ''.join([str(_) for _ in range(10)]))\n",
    "plt.yticks(np.arange(36),string.ascii_uppercase[:26] + ''.join([str(_) for _ in range(10)]))\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IibYYUsujak"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FU-Z9AwcoN2N"
   },
   "source": [
    "# Q4 Image Compression with Autoencoders\n",
    "\n",
    "An autoencoder is a neural network that is trained to attempt to copy its input to its output, but it usually allows copying only approximately. This is typically achieved by restricting the number of hidden nodes inside the autoencoder; in other words, the autoencoder would be forced to learn to represent data with this limited number of hidden nodes. This is a useful way of learning compressed representations.\n",
    "\n",
    "In this section, we will continue using the NIST36 dataset you have from the previous questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68an5919obx0"
   },
   "source": [
    "## Q4.1 Building the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8Yis3yooiup"
   },
   "source": [
    "### Q4.1 (4 points)\n",
    "\n",
    "Due to the difficulty in training auto-encoders, we have to move to the $relu(x) = max(x,0)$ activation function. It is provided for you. We will build an autoencoder with the layers listed below. Initialize the layers with the initialize_weights() function you wrote in Q2.1.2.\n",
    "\n",
    "- 1024 to 32 dimensions, followed by a ReLU\n",
    "- 32 to 32 dimensions, followed by a ReLU\n",
    "- 32 to 32 dimensions, followed by a ReLU\n",
    "- 32 to 1024 dimensions, followed by a sigmoid (this normalizes the image output for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yHIN01ZpQSx"
   },
   "outputs": [],
   "source": [
    "# here we provide the relu activation and its derivative for you\n",
    "from collections import Counter\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "############################## Q 4.1 ##############################\n",
    "params = Counter()\n",
    "\n",
    "# initialize layers here\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8rMh7WtqKYe"
   },
   "source": [
    "## Q4.2 Training the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9a0VtkVqHIH"
   },
   "source": [
    "### Q4.2.1 (5 points)\n",
    "\n",
    "To help even more with convergence speed, we will implement momentum. Now, instead of updating $W = W - \\alpha \\frac{\\partial J}{\\partial W}$, we will use the update rules $M_W = 0.9 M_W - \\alpha \\frac{\\partial J}{\\partial W}$ and $W = W + M_W$. To implement momentum, populate the parameters dictionary with zero-initialized momentum accumulators M, one for each parameter. Then simply perform both update equations for every batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqbxdt0wqsAh"
   },
   "source": [
    "### Q4.2.2 (6 points)\n",
    "\n",
    "Using the provided default settings, train the network for 100 epochs. The loss function that you will use is the total squared error for the output image compared to the input image (they should be the same!). Plot the training loss curve. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 124849,
     "status": "ok",
     "timestamp": 1711076695777,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "EvO8GWRtq2w5",
    "outputId": "b945225e-5d9a-4ebb-b5e3-a89ae3607357"
   },
   "outputs": [],
   "source": [
    "########################### Q 4.2.1 & Q 4.2.2 ########################\n",
    "# the NIST36 dataset\n",
    "train_data = scipy.io.loadmat('/content/data/nist36_train.mat')\n",
    "valid_data = scipy.io.loadmat('/content/data/nist36_valid.mat')\n",
    "\n",
    "# we don't need labels now!\n",
    "train_x = train_data['train_data']\n",
    "valid_x = valid_data['valid_data']\n",
    "\n",
    "max_iters = 100\n",
    "# pick a batch size, learning rate\n",
    "batch_size = 36\n",
    "learning_rate =  3e-5\n",
    "hidden_size = 32\n",
    "lr_rate = 20\n",
    "batches = get_random_batches(train_x,np.ones((train_x.shape[0],1)),batch_size)\n",
    "batch_num = len(batches)\n",
    "\n",
    "# should look like your previous training loops\n",
    "losses = []\n",
    "for itr in range(max_iters):\n",
    "    total_loss = 0\n",
    "    for xb,_ in batches:\n",
    "        # training loop can be exactly the same as q2!\n",
    "        # your loss is now the total squared error, i.e. the sum of (x-y)^2\n",
    "        # delta is the d/dx of (x-y)^2\n",
    "        # to implement momentum\n",
    "        #   just use 'M_'+name variables as momentum accumulators to keep a saved value over steps\n",
    "        #   params is a Counter(), which returns a 0 if an element is missing\n",
    "        #   so you should be able to write your loop without any special conditions\n",
    "\n",
    "        ##########################\n",
    "        ##### your code here #####\n",
    "        ##########################\n",
    "\n",
    "\n",
    "    losses.append(total_loss/train_x.shape[0])\n",
    "    if itr % 2 == 0:\n",
    "        print(\"itr: {:02d} \\t loss: {:.2f}\".format(itr,total_loss))\n",
    "    if itr % lr_rate == lr_rate-1:\n",
    "        learning_rate *= 0.9\n",
    "\n",
    "# plot loss curve\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"average loss\")\n",
    "plt.xlim(0, len(losses)-1)\n",
    "plt.ylim(0, None)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxeoGSwXvPe6"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKBtWoyUviCi"
   },
   "source": [
    "## Q4.3 Evaluating the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6ymhRoFvfNY"
   },
   "source": [
    "### Q4.3.1 (5 points)\n",
    "\n",
    "Now let's evaluate how well the autoencoder has been trained. Select 5 classes from the total 36 classes in the validation set and for each selected class show 2 validation images and their reconstruction. What differences do you observe in the reconstructed validation images compared to the original ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 3730,
     "status": "ok",
     "timestamp": 1711076871480,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "NpcI9jxkvd4c",
    "outputId": "b9e72a42-7b62-474f-b1c2-dc9f9e5e667a"
   },
   "outputs": [],
   "source": [
    "############################## Q 4.3.1 ##############################\n",
    "# choose 5 classes (change if you want)\n",
    "visualize_labels = [\"H\", \"3\", \"U\", \"8\", \"Q\"]\n",
    "\n",
    "# get 2 validation images from each label to visualize\n",
    "visualize_x = np.zeros((2*len(visualize_labels), valid_x.shape[1]))\n",
    "for i, label in enumerate(visualize_labels):\n",
    "    idx = 26+int(label) if label.isnumeric() else string.ascii_lowercase.index(label.lower())\n",
    "    choices = np.random.choice(np.arange(100*idx, 100*(idx+1)), 2, replace=False)\n",
    "    visualize_x[2*i:2*i+2] = valid_x[choices]\n",
    "\n",
    "# run visualize_x through your network\n",
    "# using the forward() function you wrote in Q2.2.1\n",
    "reconstructed_x = visualize_x\n",
    "# TODO: name the output reconstructed_x\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n",
    "\n",
    "\n",
    "# visualize\n",
    "fig = plt.figure()\n",
    "plt.axis(\"off\")\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(len(visualize_labels), 4), axes_pad=0.05)\n",
    "for i, ax in enumerate(grid):\n",
    "    if i % 2 == 0:\n",
    "        ax.imshow(visualize_x[i//2].reshape((32, 32)).T)\n",
    "    else:\n",
    "        ax.imshow(reconstructed_x[i//2].reshape((32, 32)).T)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VJKbdK9wPJb"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UaApE55wdqV"
   },
   "source": [
    "### Q4.3.2 (5 points)\n",
    "\n",
    "Let’s evaluate the reconstruction quality using Peak Signal-to-noise Ratio (PSNR). PSNR is defined as\n",
    "\n",
    "$$\\text{PSNR} = 20 \\times \\log_{10}(\\text{MAX}_I) - 10\\times \\log_{10}(\\text{MSE})$$\n",
    "\n",
    "where $\\text{MAX}_I$ is the maximum possible pixel value of the image, and $\\text{MSE}$ (mean squared error) is computed across all pixels. Said another way, maximum refers to the brightest overall sum (maximum positive value of the sum). You may use skimage.metrics.peak_signal_noise_ratio for convenience. Report the average PSNR you get from the autoencoder across all images in the validation set (it should be around 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1711076882180,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "Jxg6aN3RwkfI",
    "outputId": "a91d81c1-7f83-4e5c-f22c-7608fa5c095a"
   },
   "outputs": [],
   "source": [
    "############################## Q 4.3.2 ##############################\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "# evaluate PSNR\n",
    "##########################\n",
    "##### your code here #####\n",
    "##########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxqdG4EASIhS"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBTCj6cg3sl7"
   },
   "source": [
    "# Q5 (Extra Credit) Extract Text from Images\n",
    "\n",
    "Run below code to download and put the unzipped data in '/content/images' folder. We have provided you with 01_list.jpg, 02_letters.jpg, 03_haiku.jpg and 04_deep.jpg to test your implementation on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrgM0lsQ4IF6"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/content/images'):\n",
    "  os.mkdir('/content/images')\n",
    "  !wget http://www.cs.cmu.edu/~lkeselma/16720a_data/images.zip -O /content/images/images.zip\n",
    "  !unzip \"/content/images/images.zip\" -d \"/content/images\"\n",
    "  os.system(\"rm /content/images/images.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1711076479518,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "BLEuTPhv4dNE",
    "outputId": "d3d5a14e-3444-4fc2-fc17-042298334631"
   },
   "outputs": [],
   "source": [
    "ls /content/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TB6CS344e7n"
   },
   "source": [
    "## Q5.1 (Extra Credit) (4 points)\n",
    "\n",
    "The method outlined above is pretty simplistic, and while it works for the given text samples, it makes several assumptions. What are two big assumptions that the sample method makes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKTCXAR34t3U"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE...\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCMMeUWm6B_i"
   },
   "source": [
    "## Q5.2 (Extra Credit) (10 points)\n",
    "\n",
    "Implement the findLetters() function to find letters in the image. Given an RGB image, this function should return bounding boxes for all of the located handwritten characters in the image, as well as a binary black-and-white version of the image im. Each row of the matrix should contain [y1,x1,y2,x2], the positions of the top-left and bottom-right corners of the box. The black-and-white image should be between 0.0 to 1.0, with the characters in white and the background in black (consistent with the images in nist36). Hint: Since we read text left to right, top to bottom, we can use this to cluster the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdgBYjnP4tM6"
   },
   "outputs": [],
   "source": [
    "############################## Q 5.2 ##############################\n",
    "def findLetters(image):\n",
    "    \"\"\"\n",
    "    takes a color image\n",
    "    returns a list of bounding boxes and black_and_white image\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    bw = None\n",
    "    # insert processing in here\n",
    "    # one idea estimate noise -> denoise -> greyscale -> threshold -> morphology -> label -> skip small boxes\n",
    "    # this can be 10 to 15 lines of code using skimage functions\n",
    "\n",
    "    ##########################\n",
    "    ##### your code here #####\n",
    "    ##########################\n",
    "\n",
    "\n",
    "    return bboxes, bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maR0-2tf7FMC"
   },
   "source": [
    "## Q5.3 (Extra Credit) (3 points)\n",
    "\n",
    "Using the provided code below, visualize all of the located boxes on top of the binary image to show the accuracy of your findLetters() function. Include all the provided sample images with the boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7352,
     "status": "ok",
     "timestamp": 1711076486867,
     "user": {
      "displayName": "Xinyu Li",
      "userId": "09039469784461782839"
     },
     "user_tz": 240
    },
    "id": "zkVQX71k7KjQ",
    "outputId": "774a6a27-a2b8-40f3-8326-436bb06b65c4"
   },
   "outputs": [],
   "source": [
    "############################## Q 5.3 ##############################\n",
    "# do not include any more libraries here!\n",
    "# no opencv, no sklearn, etc!\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "for imgno, img in enumerate(sorted(os.listdir('/content/images'))):\n",
    "    im1 = skimage.img_as_float(skimage.io.imread(os.path.join('/content/images',img)))\n",
    "    bboxes, bw = findLetters(im1)\n",
    "\n",
    "    print('\\n' + img)\n",
    "    plt.imshow(1-bw, cmap=\"Greys\") # reverse the colors of the characters and the background for better visualization\n",
    "    for bbox in bboxes:\n",
    "        minr, minc, maxr, maxc = bbox\n",
    "        rect = matplotlib.patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                fill=False, edgecolor='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysnlG_hR8Kv3"
   },
   "source": [
    "## Q5.4 (Extra Credit) (8 points)\n",
    "\n",
    "You will now load the image, find the character locations, classify each one with the network you trained in Q3.1, and return the text contained in the image. Be sure you try to make your detected images look like the images from the training set. Visualize them and act accordingly. If you find that your classifier performs poorly, consider dilation under skimage morphology to make the letters thicker.\n",
    "\n",
    "Your solution is correct if you can correctly detect most of the letters and classify approximately 70\\% of the letters in each of the sample images.\n",
    "\n",
    "Run your code on all the provided sample images in '/content/images'. Show the extracted text. It is fine if your code ignores spaces, but if so, please provide a written answer with manually added spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYqoWv8TMNdO"
   },
   "outputs": [],
   "source": [
    "############################## Q 5.4 ##############################\n",
    "for imgno, img in enumerate(sorted(os.listdir('/content/images'))):\n",
    "    im1 = skimage.img_as_float(skimage.io.imread(os.path.join('/content/images',img)))\n",
    "    bboxes, bw = findLetters(im1)\n",
    "    print('\\n' + img)\n",
    "\n",
    "    # find the rows using..RANSAC, counting, clustering, etc.\n",
    "    ##########################\n",
    "    ##### your code here #####\n",
    "    ##########################\n",
    "\n",
    "\n",
    "\n",
    "    # crop the bounding boxes\n",
    "    # note.. before you flatten, transpose the image (that's how the dataset is!)\n",
    "    # consider doing a square crop, and even using np.pad() to get your images looking more like the dataset\n",
    "    ##########################\n",
    "    ##### your code here #####\n",
    "    ##########################\n",
    "\n",
    "\n",
    "\n",
    "    # load the weights\n",
    "    # run the crops through your neural network and print them out\n",
    "    import pickle\n",
    "    import string\n",
    "    letters = np.array([_ for _ in string.ascii_uppercase[:26]] + [str(_) for _ in range(10)])\n",
    "    params = pickle.load(open('/content/q3_weights.pickle','rb'))\n",
    "    ##########################\n",
    "    ##### your code here #####\n",
    "    ##########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfC7rvFh_HxH"
   },
   "source": [
    "---\n",
    "\n",
    "YOUR ANSWER HERE... (if your code ignores spaces)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
